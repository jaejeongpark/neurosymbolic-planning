import numpy as np
from scipy.io import loadmat

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam


class NNController():
    def __init__(self, params, x_dim, u_dim):
        self.x_dim, self.u_dim = x_dim, u_dim
        self.params = params

    def load_samples(self, data_dir):
        """ Load expert trajectories """
        matfile  = data_dir + 'expert.mat'
        cells_file = loadmat(matfile)
        x_trajs = cells_file['x_trajs'][0]
        u_trajs = cells_file['u_trajs'][0]
        num_traj = x_trajs.shape[0]
        print('\nLoading expert trajectories...')
        print('Number of expert trajectories: ', num_traj)
        #print('x_trajs shape: ', x_trajs.shape)
        #print('u_trajs shape: ', u_trajs.shape)
        #print('Example trajectory and inputs:')
        #print(x_trajs[0])
        #print(u_trajs[0])
        # Remove the last state in each trajectory
        for i in range(num_traj):
            x_trajs[i] = x_trajs[i][:-1]
        X = x_trajs[0]
        y = u_trajs[0]
        for i in range(1, num_traj):
            X = np.concatenate((X, x_trajs[i]))
            y = np.concatenate((y, u_trajs[i]))
        return X, y

    def build_model(self):
        # 2 layers
        layer1_size = 10 #10
        layer2_size = 10 #10
        #layer3_size = 20
        #layer4_size = 128
        model = Sequential()
        model.add(Dense(layer1_size, input_shape=(self.x_dim+1,), activation='relu'))
        model.add(Dense(layer2_size, activation='relu'))
        #model.add(Dense(layer3_size, activation='relu'))
        #model.add(Dense(layer4_size, activation='relu'))
        model.add(Dense(self.u_dim))
        return model

    def train(self, model, X, y, data_type, if_compile):
        """ Train NN with either "expert" data or data generated by the current "symbolic" controller """
        if data_type == 'expert':
            print('\nImitation learning with expert data...')
            print('epochs: %d\n' % self.params['expert_epochs'])
            epochs     = self.params['expert_epochs']
            batch_size = self.params['expert_batch_size']
        elif data_type == 'symbolic':
            print('\nImitation learning with symbolic data...')
            epochs     = self.params['symbolic_epochs']
            batch_size = self.params['symbolic_batch_size']
        else:
            assert False, 'Unrecognized data_type'
        #print('X shape:', X.shape)
        #print('y shape:', y.shape)
        if if_compile:
            # Repeated compile does not hurt, except loses optimizer states.
            model.compile(loss='mse', optimizer='adam', metrics=['mae'])
        model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)
        return model
